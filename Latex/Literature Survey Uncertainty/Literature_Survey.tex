\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[a4paper,top=3cm,bottom=3cm,left=3cm,right=3cm,%
bindingoffset=0mm]{geometry}
\usepackage{amssymb}
\usepackage{amsmath}
\newtheorem{prop}{Proposition}
\newtheorem{lemma}{Lemma}
\newenvironment{proof}[1][Proof]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newcommand{\qed}{\nobreak \ifvmode \relax \else
      \ifdim\lastskip<1.5em \hskip-\lastskip
      \hskip1.5em plus0em minus0.5em \fi \nobreak
      \vrule height0.75em width0.75em depth0em\fi}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{rotating}
\usepackage{float}
\linespread{1.3}
\raggedbottom




%
\font\reali=msbm10 at 12pt
% subsets of real numbers
\newcommand{\real}{\hbox{\reali R}}
\newcommand{\realp}{\hbox{\reali R}_{\scriptscriptstyle +}}
\newcommand{\realpp}{\hbox{\reali R}_{\scriptscriptstyle ++}}
\newcommand{\R}{\mathbb{R}}
\DeclareMathOperator{\E}{\mathbb{E}}
%

\title{Related Literature}
\author{Marco Brianti}
\date{A.Y. 2018/2019}

\begin{document}
	\large{

\maketitle

\tableofcontents

\section{Angeletos and La'O (2010) - NBER Macroeconomics Annual}

They introduce heterogeneous information in a Real Business Cycle model. This assumption can have profound implications for the business cycle. They analyze a standard RBC model with no capital augmented with dispersed information frictions. In particular, economic decisions have to be made under heterogeneous information about the aggregate shocks hitting the economy. They summarize their results as follows. (i) Dispersed information induces inertia in the response of macroeconomic outcomes. (ii) Dispersion of information induces technology shocks to explain only a small fraction of the high-frequency variation in the business cycle. (iii) The drivers of the residual variation in the short-run fluctuations is simply the noise in available information, i.e. correlated errors in the agents' expectations of the fundamental shocks. (iv) These noise-driven fluctuations help formalize a certain type of demand shocks. (v) If a social planner takes information dispersion as given then equilibrium is already efficient implying no room for any intervention.

Importantly, what drivers their results is not per se the level of uncertainty about the underlying fundamental but rather the lack of common knowledge about it. Indeed, their effects are consistent with an arbitrary small level of uncertainty about the underlying fundamentals. However, at the same time, the lack of common knowledge alone does not explain the magnitude of our effects. What they need is also a degree of strategic complementary, which means that dispersed information has an effect if agents care on other agents' choices. Their findings hinge on the combination of heterogeneous information with strong strategic complementarity - but they do not hinge on the level of uncertainty about underlying fundamentals. In addition, notice that standard noise-shock literature obtains fluctuations that vanish when uncertainty on fundamentals is small enough.

Fluctuations are not generated by uncertainty regarding future exogenous fundamentals but by uncertainty regarding future choices of other agents that have different information. Specifically, when information is asymmetric agents face additional uncertainty about the level of economic activity beyond the one they face about fundamentals. It is specifically this feature that differentiated dispersed information different from uncertainty in fundamentals. Conversely, strategic complementary is irrelevant for business cycle fluctuations when information is commonly shared. Interestingly, the larger the level of strategic complementarity the less agents focus on fundamental shocks and the more they focus on public signals attempting to coordinate with each other. Thus, it follows that stronger strategic complementarity induces equilibrium to be more anchored to the past aggregate fundamentals, more sensitive to public information and less sensitive to private information.

Another important point that they stress is that the variance of the idiosyncratic signal received by agents is different from the degree of information dispersion. For example, if the variance of the idiosyncratic noise rises, agents might decide to rely less on their private signal focusing more on the public signal converging expectations and thus decreasing information dispersion. 


\section{Andrade, Crump, Eusepi, and Moench (2016) - JME}

They study a collection of individual forecasts of real output growth, CPI Inflation and the FFR from the Blue Chip Financial Forecasts (BCFF) survey. They use this dataset to establish three novel stylized facts about forecasters' disagreement. (i) Forecasters disagree both about the sort term but also the medium- and long-run prospects of the economy. (ii) The disagreement among forecasters is time varying, even for long-term forecasts. (iii) The shape of the term structure of disagreement differs markedly across variables. In particular, the term structure of disagreement for GDP is upward sloping, for inflation fairly flat and for the policy rate downward sloping. 

Thus, they rationalize those three key empirical facts with a generalized model of informational frictions which extends the Mankiw and Reis (2002) sticky information framework in two crucial dimensions. (i) It allows for a multivariate setup where agents update information about individual variables at different points in time. (ii) Macroeconomic variables are driven by unobserved short-term and long-term components, introducing an additional filtering problem for the agents. Notice that their model assumes that for each variable and in each period a random fraction of agents does not observe that variable realization. As a result, they do not assume that some agents are systematically more informed than others as in other models previously developed. This is an appealing property in light of the widely documented result that it is difficult to beat consensus forecasts of both survey participants and econometric models. The sticky information model captures the costs of processing the information available to produce a forecast update in the spirit of a rational inattention model. Interestingly, in their model disagreement is an increasing function of both noise and uncertainty. 

The successfully calibrate the model to match previous empirical facts. They only struggle to reproduce the unconditional variance of disagreement over time. They also show that model's feature is able to rationalize disagreement on long-term policy rate accordingly with a standard policy rule.

\section{Basu and Bundick (2017) - Econometrica}

They argue that macroeconomic comovement is a key empirical feature of the economy's response to an uncertainty shock. Using a structural vector regression (VAR), they identify an uncertainty shock in the data as an exogenous increase in the implied volatility of future stock returns. They use a Cholesky decomposition with the VXO ordered first. This ordering assumes that uncertainty shocks can have an immediate impact on output and its components, but non-uncertainty shocks do not affect the implied stock market volatility impact. Empirically, an uncertainty shock causes statistically significant declines in output, consumption, investment, and hours, with a peak response occurring after about one year. 

Under reasonable assumptions, an increase in uncertainty about the future induces precautionary saving and lowers consumption. Similarly, since both consumption and leisure are normal goods, an increase in uncertainty also induces precautionary labor supply. As current technology and the capital stock remain unchanged, the competitive demand for labor remains unchanged as well. Thus, higher uncertainty reduces consumption but raises output, investment, and hours worked. Yet intuition suggests that the reduction in household expenditure resulting from increased uncertainty could lead to a general decline in output and its components. This intuition is typically correct in models where output is demand-determined (at least over some horizon). In these models, the reduction of consumption demand reduces output and labor input which in turn reduces the demand for capital and hence investment. Aggregate demand-determined output is made consistent with household and firm optimization through endogenous movements in markups which in their model is driven by the standard assumption of nominal price rigidity.

To analyze the quantitative impact of uncertainty shocks, they calibrate and solve a representative-agent, dynamic, stochastic general-equilibrium (DSGE) model with capital accumulation and price rigidity. They examine the effects of second-moment shocks to household discount factors, which they interpret as demand uncertainty. When prices adjust slowly, uncertainty shocks can produce contractions in output and all its components. They calibrate the model using a mixed strategy between IRF-matching and unconditional moment matching. Using simulated data from their model, they show that their empirical identification strategy can recover the true macroeconomic effects of higher uncertainty. 


\section{Jurado, Ludvigson, and Ng (2015) - AER}


At a general level, uncertainty is typically defined as the conditional volatility of a disturbance that is unforecastable from the perspective of economic agents. In general equilibrium settings, reasonable mechanisms imply a role for time-varying uncertainty. A challenge in empirically examining the behavior of uncertainty, and its relation to macroeconomic activity, since no objective measure of uncertainty exists. Unfortunately, the conditions under which common proxies already used in the literature are likely to be tightly linked to the typical theoretical notion of uncertainty may be quite special. Their goal is to provide superior econometric estimates of uncertainty that are free as possible from theoretical impositions and specific-variable fluctuations. \textbf{They emphasize that what matter for economic decision making is not whether particular economic indicators have become more or less variable or disperse per se, but rather whether the economy has become more or less predictable; that is, less or more uncertain.} This implies that the proper measurement of uncertainty requires removing the forecastable component before computing conditional volatility.

Definition of uncertainty of variable $y$ at horizon $h$ given the information set at time $t$:
$$
U_t^y(h) = \sqrt{\E \big[  (y_{t+h} - \E[ y_{t+h}| I_t])^2 | I_t \big]}
$$
Two features of this definition need to be emphasized:
\begin{enumerate}
	\item The proper measurement of uncertainty requires removing the forecastable component $\E[y_{t+h}|I_t]$ before computing conditional volatility. Failure to do so will confound volatility of the variable into uncertainty.
	\item Macro uncertainty is not uncertainty of variable $y$. Instead, it is a measure of the common variation in uncertainty across many series. This common variation is critical for the study of business cycles because if the variability of the idiosyncratic shock were entirely idiosyncratic, it would have no influence on macroeconomic variables.
\end{enumerate}

A crucial first step in our analysis is to construct a forecast of variable $y$ at horizon $h$ conditional on information set at time $t$ from which they construct the forecast error that forms the basis of their uncertainty measure. Most popular measures of uncertainty do not take these systematic forecasting relationships into account.\footnote{They emphasize that stock market volatility measures do not purge movements in the stock market of its predictable component and are therefore estimates of conditional volatility, not uncertainty. Of course, if there were no predictable component in the stock market, these two estimates would coincide.} In order to identify a true forecast error, it is important that our predictive model be as rich as possible, so that our measured forecast error is purged of predictive content. To address this problem, they use the method of \textbf{diffusion index forecasting} whereby a relative small number of factors estimated from a large dataset (which includes both macro and financial variables) are augmented to a standard forecasting model.\footnote{They use final revised (historical) data in order to avoid an upward bias of the estimated uncertainty. Indeed, they want the best possible forecast to be sure to control for expectation of variable $y$ at horizon $h$.} An important feature of their analysis is that they assume that dependent variable $y$, factors from the large dataset and control variables have time-varying volatility. These features generate time-varying uncertainty in variable $y$. Thus, uncertainty at time $h$ can be represented as the evolution of previous uncertainty plus the standard deviation in the current forecast error. As $h$ increases uncertainty is less varying since it tends to its unconditional value. The key stochastic volatility parameters are estimated from the least square residuals of the forecasting models using MCMC methods. Simple averaging is used to obtain an estimate of $h$ period ahead macro uncertainty.\footnote{Elements of this average are a large set of macro variables plus $25$ financial indicators. Implying that their measure is a proxy of a general level of uncertainty in the economy.}

\textbf{Descriptive Evidence.} First, the estimated half-life of a shock to aggregate uncertainty is 53 months (using an AR(k) model) while for the VXO is only 4 months. Thus, macro uncertainty is much more persistent that the most common proxy for uncertainty. Second, the skewness of macro uncertainty is similar to VXO but the kurtosis is much lower. This implies that there are more extreme values in VXO. Third, aggregate uncertainty is strongly counter cyclical and has a contemporaneous correlation with industrial production growth rate: -0.62. Moreover, a substantial part of the comovement is attributable to uncertainty leading real activity: correlation is -0.67 when uncertainty is lagged trice with respect to industrial production growth rate. Of course, these unconditional correlations are uninformative about the causal relation between uncertainty and real activity. All that can be said is that there is a strong coherence between uncertainty and real activity. 

Existing empirical research on uncertainty had often found important dynamic relationships between real activity and various uncertainty proxies. In particular, these proxies are countercyclical and VAR estimates suggest that they have a large impact on output and employment in the months after an innovation these measures.\footnote{A key result is that a rise in some proxies (notably stock market volatility) at first depresses real activity and then increases it, leading to an over-shoot of its lung-run level. Marco: this story is consistent with the news shock literature. News may be contractionary on impact. Moreover, if SP increases then also realized stock market volatility increase. Endogenous shit!}

Using an 11-variable monthly macro VAR and recursive identification procedure with uncertainty placed last, they find that common macro uncertainty shocks account for up to 29 percent of the forecast error variance in industrial production.\footnote{Placing uncertainty last means that they are controlling for all the previous innovations. Much information is remove in their exercise.} This means that their estimates imply rare uncertainty episodes which are large, persistent and strongly related to economic activity. Although they find that increases in uncertainty are associated with large declines in real activities, they admit that their results are silent on whether uncertainty is the cause or effect of such declines. Their estimates do, however, imply that the economy is objectively less predictable in recession than it is in normal times. This result is not a statement about changing subjective perceptions of uncertainty in recessions as compared to booms. Any theory theory for which uncertainty is entirely the effect of recessions would need to be consistent with these basic findings.



\section{Bloom (2014) - JEP}

Frank Knight in 1921 defined uncertainty as peoples' inability to forecast the likelihood of events happening. In this article, Bloom refers to uncertainty as a broad mixture of risk and uncertainty. He addresses 4 questions about uncertainty. 1. What are some facts and patterns about economic uncertainty? 2. Why does uncertainty vary during business cycles? 3. Do fluctuation in uncertainty affect behavior? 4. Has higher uncertainty worsened the Great Recession and slowed the recovery?

\begin{enumerate}
	
	\item First fact regarding uncertainty is that macro uncertainty rises in recessions. For example, VIX index of 30-days implied volatility on Standard \& Poor's 500 stock market index is clearly countercyclical, rising by 58 percent on average in recessions. A second fact is that micro uncertainty rises in recessions. At every level (industries, firms, plants, \dots), uncertainty appears to rise during recessions. For example, Campbell et al. (2001) report that cross-firm stock-return variation is almost 50 percent higher in recession that booms. Third, since unemployment rises during recession so the volatility of household incomes will rise as well. However, also wages for even those who are employed also become more volatile during recessions. Finally, uncertainty is higher for developing countries.
	
	\item What factors might be causing these variations in uncertainty? In general, dramatic shocks seem to shake people's confidence in their forecasts of economic growth, raising macro and micro uncertainty. Conversely, positive shocks do not have a large impact on uncertainty. An explanation might be that positive news tend to develops gradually (internet, \dots). The theory literature highlights four mechanisms through which recessions might increase uncertainty. (i) During expansions firms are trading actively which help to generate and spread information. (Viceversa during recessions.) (ii) Individuals are more confident in predicting the future when business as usual prevails in growing economy. Recessions are rare events and since individuals are unfamiliar with them, they find harder to provide good forecasts. (iii) Unconventional or unusual policies to fight recessions may rise uncertainty. (iv) When business cycle is slack is more convenient to divert unused resources in R\&D. This dynamic leads to larger macro uncertainty since outcomes are ex ante unclear. 
	
	Uncertainty tends to be higher in developing countries because they are (i) less-diversified economies, (ii) appear to have more domestic political shocks (revolutions, \dots) or natural disasters (epidemics, \dots), and (iii) have less effective stabilization policies.
	
	\item To what extend uncertainty matters? Theoretically speaking many channels can affect real activities through uncertainty. \textbf{Real Options.} The idea is that firms can look at their investment choices as a series of options. As a result, uncertainty makes firms cautious about actions like investment and hiring, which adjustment costs can make expensive to reverse. In addition, real-options channel makes economic actors less sensitive to changes in business conditions. this can make countercyclical economic policy less effective. Notice that this channel whereby uncertainty reduces firms' sensitivity also provides an explanation for procyclical productivity. When uncertainty is high, productive firms are less aggressive in expanding and unproductive firms are less aggressive in contracting. The high uncertainty makes both of them more cautious implying a slowdown in productivity. \textbf{Risk Aversion and Risk Premia.} Investors want to be compensated for higher risk, and because greater uncertainty leads to increase risk premia this should raise the cost of finance. Moreover, a rise in uncertainty leads consumers to increase their precautionary saving, which reduces consumption expenditure. Weak consumption demand is contractionary in partially demand-driven models or in open economy (Fernandez-Villaverde et al. 2011). \textbf{Growth Options.} When business cycle is slack is more convenient to divert unused resources in R\&D. Although this dynamic leads to larger macro uncertainty since outcomes are ex ante unclear, it also leads to larger TFP growth in the long run. \textbf{Oi-Hartman-Abel Effects.} This effect highlights the possibility that if firms can expand to exploit good outcomes and contract to insure against bad outcomes, they may be risk loving. However, for this mechanism to work, firms need to be able to easily expand or contract in response to good or bad news. 
	
	Empirically speaking, the evidence on the impact of uncertainty is limited because of the difficulties in stripping out cause and effect. To identify the causal impact of uncertainty on firms and consumers, the literature has taken three approaches: (i) Estimating the movements in output, hiring, and investment that follow jumps in uncertainty. (ii) Analyzing structural models calibrated from macro and micro moments to quantify the potential effect of uncertainty shocks. (iii) Exploiting natural experiments where uncertainty arise from exogenous events. 
	
	\item Which is the role of uncertainty during the Great Recession and its aftermath? Policymakers clearly think uncertainty has played a central role in driving the Great Recession and slow recovery. However, the econometric evidence is really no more than suggestive. 
\end{enumerate}


\section{Berger, Dew-Becker, and Giglio (2019) - REStud}

This paper aims to estimate the magnitude of the effects of aggregate uncertainty shocks on economic activity. The major identification problem they face is that uncertainty about the future tends to be related to current economic conditions. Their key distinction from past work is to construct shocks to uncertainty that are orthogonal to current (relized) volatility. \textbf{Realized volatility} measures how large are the shocks that have just occurred, whereas \textbf{uncertainty} (implied volatility) is about how large agents expect future shocks to be. Models of the effects of uncertainty are driven by variation in agents' subjective distributions of future shocks, as opposed to the variance of the distribution from which today's shocks were drawn. Past work found that shocks to stock market volatility, measured as a mixture of realized and expected future volatility, have negative effects on the economy. They show that the distinction between realized volatility and news about the future (implied volatility) is critical for understanding the effects of uncertainty shocks. When uncertainty shocks are properly defined as forward looking, they actually have no effects on the economy. Rather it is current realized volatility that is associated with downturns and drives the previous results. While there are many models explaining how uncertainty shocks might drive the economy, there are no current models available matching our findings that uncertainty shocks are not contractionary while realized volatility shocks are.  The last section of the paper presents a simple purely rational model that quantitatively matches our evidence. Its key mechanism is that shocks to technology are negatively skewed. Negative skewness means that large shocks - which cause high realized volatility - also tend to be negative shocks, immediately generating the observed negative correlation between realized volatility and output. Their finding that realized volatility per se is associated with contractions does not therefore imply that realized volatility per se is contractionary - it can be simply capturing the occurrence of a large negative shock.\footnote{This is what they say: A jump in stock prices, such as a crash or the response to a particularly bad macro data announcement, mechanically generates high realized volatility. On the other hand, news about future uncertainty, such as an approaching presidential election, increase expected volatility. \textit{I personally do not believe that high nonfundamental news does not affect stock prices. This is not what I expect. I need to dig in. Indeed, realized volatility and implied volatility have correlation extremely close to 1. If an uncertainty shock cannot have impact on realized volatility then what is left?}}

Empirically, they ran a Structural VAR with aggregate monthly US data which embodies realized volatility, implied volatility, industrial production, and employment. All variables are in log. Realized volatility is defined as the monthly average of the daily stock return of the S\&P 500 index. Implied volatility is extremely close to the VIX and other relater model-free implied volatility. They identify a realized volatility shock as the residual of realized volatility from the reduced-form VAR (as a Cholesky identification with realized volatility ordered first). They identify an uncertainty shock (implied-volatility shock) as a shock that have zero-impact effect on realized volatility and whose variance of expected future realized volatility is equal to the one explained by a realized volatility shock on the same variable. They obtain that a realized volatility shock is associated with contractions on both employment and industrial production capturing the intuition that higher realized volatility is related to large negative (fundamental) shocks. Surprisingly, an uncertainty shock has no effect on employment and industrial production when using sufficiently tight confidence bands. 


\section{Leduc and Liu (2016) - JME}

In the empirical section they examines the macroeconomic effects of uncertainty shocks in the data. They consider two alternative measures of uncertainty: (i) VIX and (ii) a new measure of consumers' perceived uncertainty constructed from the University of Michigan Surveys of Consumers. This last measure asks consumers if they are going to buy or not a durable good in the next period and the reason why they are not going to buy it. Among the options there is also uncertain future. They broadly use this specific type of answer to measure uncertainty. Although the time series behaviors of these two measures of uncertainty are quite different, the macroeconomic effects of uncertainty shocks based on the two different measures are remarkably similar. 

The baseline BVAR contains four time-series variables: 1. a measure of uncertainty, 2. the unemployment rate, 3. the inflation rate (CPI), and 4. the 3-month Treasury bills rate. Thus, they use a Choleski decomposition which implies that the uncertainty variable does not respond to macroeconomic shocks in the impact period, but macro variables are allowed to respond to an uncertainty shock. Similarly to Basu and Bundick (2017) an uncertainty shock is contractionary with an effect that last at most 4 years. They claim that since the impact effect on macro variables is very small an uncertainty shock can be also ordered last without deeply affecting the result. To assess the extend to which consumer uncertainty might reflect their perceptions of bad economic times, they also control in the VAR for another indicator of economic conditions: consumer sentiment index.\footnote{My personal comment is that they order this indicator as second implying that they do not control for a jump in uncertainty due to a contemporaneous fundamental shock. I am pretty sure, and I may control for it that if you reverse the ordering between the first two variables uncertainty does not explain anything as Berger et al. (2019).} 

In the theoretical section, they examine transmission channels of uncertainty shocks in a DSGE model with sticky prices and labor market search frictions. They show that an uncertainty shock in the DSGE model acts like an aggregate demand shock that raises unemployment, lowers inflation, and through the Taylor rule, lowers the nominal interest rate, as in the data. In the DSGE model, search frictions in the labor market and sticky prices in the good market are both important for amplifying the effects of uncertainty shocks. In particular, search frictions are related to the option-value channel. Uncertainty creates a precautionary motive that reduces the real interest rate. All else equal, a reduction in the real interest rate raises the present value of a job match and thus raises employment and output. However, a model with search frictions implies that a job match represents an irreversible long-term employment relation. Uncertainty then gives rise to a real option-value effect that is contractionary. Facing higher uncertainty, the option value of waiting increases and the expected value of a job match decreases, inducing firms to post fewer vacancies, making it harder for unemployed workers to find jobs, and ultimately raising the equilibrium unemployment rate. The intuition for sticky prices and policy rate is similar to the one provided by Basu and Bundick (2017).\footnote{They claim that following Born and Pfeifer (2014), in a standard model without search frictions, habit formation dampens the effect of uncertainty on economic activity, since the consumption declines is more muted in this case. In their model instead, habit formation amplifies responses.}

When the model is augmented with both frictions, simulated data generate an unemployment response to uncertainty with a size close to that estimated from the BVAR model. Thus, this interaction is important for amplifying the macroeconomic effects of uncertainty shocks. 



\section{Cascaldi-Garcia and Galvao (2019) - JMCB}

They show that news and uncertainty shocks are positively related using standard procedures. Their result is robust when they focus on financial uncertainty but not significant if they focus on macroeconomic uncertainty. When an uncertainty shock hits the economy, utilization-adjusted TFP increases over the medium run implying an attenuation bias of the negative impact of increasing uncertainty on economic activity.\footnote{I personally do not agree on the point of the attenuation bias. If the causality is correct there is no attenuation bias, this is what it is. If the causality direction is not correct then it is possible to find an attenuation bias. In other words, the attenuation bias cannot go in both directions.}

They define good uncertainty shocks the ones related to news (future increase in TFP) and bad uncertainty shocks as the ones not related to news. Obviously, bad uncertainty shocks play a larger role on over short horizon since they do not suffer of the attenuation bias of positive TFP.

News shocks are positive related to financial uncertainty in the medium run. This result has been already confirmed by Bloom (2009), Matsumoto et al. (2011), and Gortz et al. (2016). However, the persistent positive effect of financial uncertainty shocks on productivity might be seen as counterintuitive since TFP should decrease in the short run due to the effect of wait-and-see where productive firms cease to expand and non productive firms cease to contract. They shed light on this puzzle by examining the response of non-adjusted TFP to uncertainty shocks. Non-adjusted TFP is now consistent with what expected implying that responses of productivity to uncertainty shocks reflect a combination of two effects: (i) a short-lived negative effect driven by a reduction of factor utilization and (ii) a positive medium-horizon effect generated by technology improvements.  

Financial and uncertainty shocks only differ in the long-run, as uncertainty shock effects die out, whereas news shocks persist. Thus, they identify both news and uncertainty shocks in the same model such that we are able to measure their relevance in explaining business cycles variation. They use a VAR with 12 variables with aggregate quarterly US data. They define \textbf{good uncertainty shocks} the ones related to news (future increase in TFP) and \textbf{bad uncertainty shocks} as the ones not related to news, i.e. the once where they sequentially control for news. Obviously, bad uncertainty shocks play a larger role on over short horizon since they do not suffer of the attenuation bias of positive TFP. Importantly, the relative importance of news and financial uncertainty shocks depends on whether we are able to assume that technology news shocks are orthogonal to financial uncertainty.


\section{Ludvigson, Ma, and Ng (2017) - NBER WP}

A large literature in macroeconomics investigates the relationship between uncertainty and business cycle fluctuations. Interest in this topic has been spurred by a growing body of evidence that uncertainty rises sharply in recessions. But while this evidence substantiates a role for uncertainty in deep recessions, the question of whether uncertainty is an exogenous source of business cycle fluctuations or an endogenous response to economic fundamentals is not fully understood. This paper considers a novel identification strategy to disentangle the causes and consequences of real and financial uncertainty. 

Moreover, as surveyed by Ng and Wright (2013), all the post-1982 recessions have origins in financial markets, and these recessions have markedly different features from recessions where financial markets play a passive role. From this perspective, if financial shocks are subject to time-varying volatility, financial market uncertainty - as distinct from real economic uncertainty - could be a key player in recessions, both as a cause and as a propagation mechanism. Contemporaneous changes in uncertainty can arise both as a cause of business cycle fluctuations and as a response to other shocks. 

The objective of this paper is to establish a set of stylized facts that addresses these questions econometrically, against which a wide range of individual models could be evaluated. A large literature addresses the question of uncertainty and its relation to economic activity. Theories for which uncertainty plays a key role differ widely on the question of whether this correlation implies that uncertainty is primarily a cause or a consequence of declines in economic activity. In most cases, it is modeled either as a cause or a consequence, but not both. The first strand of literature proposes uncertainty as a cause of lower economic growth. This includes models of real options effects of uncertainty, models in which uncertainty influences financing constraints, or precautionary saving. These theories almost always presume that uncertainty is an exogenous shock to some economic fundamental. A second strand of literature postulates that higher uncertainty arises solely as a response to lower economic growth, emphasizing a variety of mechanisms. Some of these theories suggest that bad times incentivize risky behavior, or reduce information and with it the forecastability of future outcomes, or provoke new and unfamiliar economic policies whose effects are highly uncertain, or create a greater misallocation of capital across sectors, or generate endogenous countercyclical uncertainty in consumption growth because investment is costly to reverse. Finally, a third literature suggests that uncertainty can actually increase economic activity. Growth options theories of uncertainty postulates that a mean-preserving spread risk can cause firms to invest and hire, since the increase in mean-preserving risk increases expected profits. Yet the absence of a theoretical consensus on this matter, along with the huge number of theories and limited body of evidence on the structural elements of specific models, underscore the extent to which the question of cause and effect is fundamentally an empirical matter that must be settled in an econometric framework with as little specific theoretical structure as possible, so that various theoretical possibilities can be nested in empirical tests. 

They estimate a reduced form VAR with three variables: macro uncertainty, a measure of real activities, and financial uncertainty. To fully identify the impact matrix they need nine restrictions. Six of them are implicitly provided by the covariance matrix of residuals and three of them should be exogenously imposed. To complete those three missing restrictions they assume to have 2 instruments (one for each type of uncertainty) with the following features. 1. $Z_1$ is correlated with both types of uncertainty but uncorrelated with real activities. 2. $Z_2$ is only correlated to financial uncertainty and uncorrelated with the rest. Those two instruments provide the three missing necessary restrictions to just identify the impact matrix. However, they argue that credible external instruments for uncertainty shocks that are truly exogenous may be difficult or impossible to find and defend. Thus, they propose a methodology to construct synthetic proxy variables which should work as instruments.


A theoretical premise of the paper is that structural uncertainty shocks should be reflected in stock prices. They then pretend to be able to run two regressions: 1. stock prices on their past and current first-moment shocks, and 2. stock prices on their past, current first-moment shocks and current macro uncertainty shocks. The residual of the first regression would be $Z_1$ and the residual of the second would be $Z_2$ by construction. However, it should be obvious that first-moment shocks and macro uncertainty shocks are not available since they are in function of the three missing identifying restrictions to obtain the rotation impact matrix. This implies that this two-step identification assumption is still underidentified implying that an infinite number of impact matrix would satisfy the system. Thus, they employ two types of winnowing constraints to shrink the number of possible solutions of the impact matrix: 1. the correlation between the first instrument and both types of uncertainty should be above a threshold and the correlation between the second instrument and financial uncertainty should be above to the same threshold as well. 2. financial uncertainty shocks should be above some thresholds in two periods where financial uncertainty was considered to be particularly high and at the same time during the financial crisis the shock to real activities should be negative and below a certain threshold. Hence solutions in the unconstrained set that do not satisfy the lower bounds will be dismissed. They randomly obtain 40000 impact matrices and they only keep the ones which satisfy the constraints above.

\textbf{Results.} In general they consider uncertainty one period ahead. \textit{Financial uncertainty shocks} lead to sharp declines in real activities that persist for many months. These results support that high financial uncertainty is an exogenous impulse that causes declines in real activity. However, financial uncertainty shocks explain few (in terms of variance decomposition) of real activities in the short run, this measure increase over the medium run. \textit{Real activities shocks} have no clear effect on financial uncertainty. Moreover, macro uncertainty increases sharply after a negative real activities shock. So, higher macro uncertainty is an endogenous response to first-moment shocks. Moreover, real activities shocks have a remarkable effect on macro uncertainty in terms of variance explained but explain few of financial uncertainty. \textit{Macro uncertainty shocks} have no effects on financial uncertainty and seem to increase real activities in the short run. Surprisingly, macro uncertainty shocks explain a huge variance of economic activities. Finally their exercise rejects the Choleski identification strategy since no impact matrices have values close to zero on impact.


\section{Stock and Watson (2012) - Brookings Papers EA}

The 2007-09 recession and subsequent recovery were qualitatively and quantitatively different from previous postwar recessions. The recession also seems unprecedented in its sources: a financial sector that was unusually vulnerable because of recent deregulation and little-understood derivatives, and a collapse that also dampened the recovery. This paper takes an empirical look at this recession and recovery, with an eye toward quantifying the extend to which this recession differs from previous postwar recessions, the contributions of various shocks to the recession, and the reasons for the slow recovery.

They implement a dynamic factor model. Because a DFM has relatively few factors compared with the number of observed variables, it allows a tractable simultaneous empirical analysis of very many variables in a single, internally consistent framework. The DFM expresses each of the time series as a component driven by the factors, plus an idiosyncratic disturbance term. Moreover, factors are modeled according to a VAR model in function of lag polynomials of the same factors. To estimate the factors they use the first 6 principal components. Principal components span the same space of the factors up to a normalization problem. This arbitrary normalization means that the individual factors do not have a direct economic interpretation. The data set consists of quarterly observations on 200 US macroeconomic time series. They carefully explain how to transform, normalize and detrend them (it can be useful in future). Since the data set contains both high-level aggregates (e.g. consumption) and disaggregated components (e.g. durable and non-durable consumption, services, ...), to avoid double counting, disaggregate components were used to estimate the factors. The DFM is estimated with six factors, a choice consistent with Bai and Ng (2002).

They investigate if the 2007-09 recession exhibited new macrodynamics relative to the 1959Q1-2007Q3 experience. They consider the following experiment: suppose a forecaster in 2007Q3 had in hand their 6 factors and was also magically given a preview of those six factors from 2007Q4 to 2011Q2. Using the pre-2007Q4 model and the post-2007Q3 values of the old factors to predict crisis and post-crisis observables, how well would these predicted values track the actuals over the recession and recovery? In general, the old six factors do a great job to track the 200 observable variables in the data set. They additionally run some tests to rule out any structural break in the macrodynamics. As a result, there is little evidence of a new factor associated with the 2007-09 recession and its aftermath and the response of macro variables to those factors seems to be unchanged. Finally, there were large innovations in these old factors during the recessions. In other words, shocks were larger but still the same. 

A second challenge is to obtain an economic interpretation to those innovations, i.e. moving from innovations to structural shocks. This is typically done by first assuming that the innovations can be expressed as linear combinations of the structural shocks, then by imposing economic restrictions that permit identification of the coefficients of those linear combinations. Most identification schemes for structural VAR analysis have an instrumental variables interpretation. Simplest ones use internal instruments in the form of impact or sign restrictions. An alternative method, pioneered by Christina Romer and David Romer (1989) is to use information from outside the VAR to construct exogenous components of specific shocks directly. These exogenous components are typically treated as exogenous shocks; however, technically they are instrumental variables for the shocks: they are not the full shock series, but rather measure an exogenous component of the shock, so that the constructed series is correlated with the shock of interest but not with other shocks. We refer to these constructed series as external instruments, because they use information external to the VAR for identification that is not itself included in the VAR. Suppose one has two instruments that purportedly identify different shocks. If both instruments are valid, then in the population these identified shocks will be uncorrelated. But the population projection does not impose that the two shocks be uncorrelated; in fact, if one or both instruments are not valid, then in general the two shocks will be correlated. They use this last instrumental variable approach for six different structural shocks: oil prices, monetary policy, productivity, uncertainty, liquidity and financial risk, and fiscal policy. They provide a set of important instruments which can be useful in future. In general, a notable correlation is between sources of uncertainty shocks and sources of liquidity/financial risk shocks. The composite uncertainty-liquidity shock attributes approximately twp-thirds of the recession's decline in GDP and employment. Moreover, the contribution of productivity, monetary policy, and fiscal policy shocks are small. Oil shocks contributed to the decline, especially before the financial crisis.

Finally, focusing on the recovery following the 2009Q2 trough, most of the slowness of the recovery is attributable to a long-term slowdown in trend employment growth. The explanation for this declining trend growth rate that we find most compelling rests on changes in underlying demographic factors, primarily in the plateau in the female labor force participation rate and the aging of the workforce. These demographic changes imply continued low or even declining trend growth rates in employment, which in turn suggest that future recessions will be deeper and longer, and will have slower recoveries, than has been the case historically.

\section{Caldara, Fuentes-Albero, Gilchrist, and Zakrajsek (2016) - EER}

Empirically distinguishing between financial and uncertainty shocks, however, is difficult because increases in financial market volatility are frequently associated with significant increases in credit spreads. Episodes of acute financial distress are associated with spikes in asset price volatility. Within a SVAR framework this degree of comovement between indicators of financial distress and uncertainty proxies significantly complicates the identification of both shocks - as both types of variables are fast moving. As a result, it is difficult to impose plausible zero contemporaneous restrictions to identify both types of disturbances. It is also difficult to impose sign restrictions on the impulse response functions in order to achieve an economically plausible identification because financial and uncertainty shocks have theoretically the same qualitative effects on both prices and quantities in most instances.  


Because there is little consensus among economists on what is the best measure of economic uncertainty, they consider six different proxies: 1. Realized Stock Market Volatility in the spirit of Berger et al. (2019). 2. Option implied volatility as \textbf{VXO}. 3. Implied Stock market Volatility from Gilchrist et al. (2014). 4. Macro uncertainty from Jurado et. al (2015) (\textbf{JLN}). 5. Policy uncertainty by Baker et al. (2015). 6. Forecast dispersion (disagreement) by Bechman et al. (2013). To measure the tightness of financial market conditions, they rely on corporate bond credit spreads. Specifically, they use the excess bond premium (\textbf{EBP}) of Gilchrist and Zakrajsek (2012). They show that the cross-correlations between the EBP and uncertainty proxies are all positiveand tend to be the highest when evaluated contemporaneously. Only exception is for the measure of disagreement which seems to be correlated with some lags to EBP. 

They first explore the relative roles of uncertainty and financial conditions as predictors of the near-term of economic activity. In general, the predicted power of EBP seems to be stronger than the one of proxies of economic activities. Indeed, once the state of current financial market conditions is taken into account, it is only the JLN and forecast disagreement uncertainty measures that are informative about the trajectory of economic activities. 

To identify uncertainty and financial shocks, they employ the penalty function approach which selects a SVAR model by maximizing a criterion function subject to inequality constraints.\footnote{The inequality constraints in their case is a non-binding sign restriction that the effect of the two shocks on its own endogenous variable should be always positive.} In the baseline identification scheme, the first step identifies the uncertainty shocks as an innovation that generates the largest increase in a measure of uncertainty in the first six months. The second step identifies a financial shock which is an innovation that generates the largest increase in the EBP for the first six months and is orthogonal to the uncertainty disturbance identified by the first step. These identifying assumptions do not rule out the possibility that financial conditions might react contemporaneously to a change in economic uncertainty induced by an uncertainty shock; by the same token, macroeconomic uncertainty is allowed to change immediately in response to a financial shock. However, this strategy imposes a timing restriction since the uncertainty shock is identified first and the financial shock has to be orthogonal to it. To take this identification issue into account then they also identify both shocks inverting step 1 with step 2. They acknowledge that neither scheme fully resolves the difficulty problem of how to identify these two types of shocks in a VAR context. They view the two approaches as providing useful bounds on the role of uncertainty and financial shocks in business cycle fluctuations. To implement the two identification schemes, they employ Bayesian estimation techniques. Their monthly VAR specification consists of 10 endogenous variables: 1. Uncertainty proxy; 2. EBP; 3. Industrial production; 4. Employment; 5. Consumption; 6. PCE price deflator; 7. 2-year treasury yield; 8. 10-year treasury yield; 9. Stock market return; 10. Commodity Index from 1975M1:2015:M3 with 6 lags.

\textbf{Results.} Differently to all the other measures of uncertainty, JLN (i) has an hump-shaped response to its own shock and (ii) does not have a significant impact effect on stock prices. All the uncertainty measures lead to a decline in economic activities and a peak on financial conditions. However, once they invert the steps only JLN maintains a significant (although small) effect on financial conditions. In addition, all declines in real activities are smaller and in many cases not significant (JLN is significant). Focusing on JLN and according to which step comes first, uncertainty shocks explain between 20\% and 40\% of industrial production over the 3 years. Result is specular focusing on financial shocks. Authors conclude that these are evidence that both financial shocks and uncertainty shocks are important independent driver of economic fluctuations. They also show that a large part of this result is driven by the recent outcome of the financial crisis: without that both shocks are less relevant sources of economic fluctuations. Finally, they validate the fact that those shocks are uncorrelated with monetary policy shocks, fiscal shocks, oil shocks and unexpected TFP shocks. Correlation is low but it is difficult to say how much relevant they can be if controlling for all of them. Moreover, unexpected TFP shocks are correlated to negative 16.   



\section{Gilchrist and Zakrajsek (2012) - AER}

Between the summer of 2007 and the spring of 2009, the US economy was gripped by an acute liquidity and credit crunch, by all accounts the most severe financial crisis since the Great Depression. Throughout this period of extreme financial turmoil, credit spreads - the difference in yields between various private debt instruments and government securities of comparable maturity - served as a crucial gauge of the degree of strains of the financial system. Fluctuations in credit spreads may also reflect shifts in the effective supply of funds offered by financial intermediaries, which, in the presence of financial market frictions, have important implications for the usefulness of credit spreads as predictors of economic activity. In the latter case, a deterioration in the capital position of financial intermediaries leads to a reduction in the supply of credit, causing an increase in the cost of debt finance and a subsequent reduction in spending and production. 

In this paper, they employ the approach of Gilchrist et al. (2009) to construct a credit spread index with high information content for future economic development. The micro-level aspect of their data allows them to constrict credit spreads that are not subject to the duration mismatch. They construct a synthetic risk-free security that mimics exactly the cash flows of the corresponding corporate debt instruments. To calculate the price of the corresponding risk-free security they discount cash-flow sequence using continously compounded zero-coupon Treasury yields, obtained from the US Treasury yield curve. The difference between this synthetic risk-free security and the corresponding one is the credit spread. Their credit spread index is the simple average of all the security-specific credit spreads. Using OLS (local projection style) they show that the GZ credit spread is statistically a highly significant predictor of key aggregate measures of economic activity over 1 and 4 quarters. The magnitude of the estimated coefficients implies an economically significant negative relationship between credit spreads and future economic activity. 

In the subsequent part they decompose their high-information content credit spread index into two components: a component that captures the systematic movements in default risk of individual firms and a residual component - the excess bond premium - that represents variation in the average price of bearing exposure to US corporate credit risk, above and beyond the compensation of expected defaults. Their empirical methodology is related to Berndt et al. (2008) who assume that the log of credit spread is linearly related to a firm-specific measure of expected default and a vector of bond-specific characteristics. They then regress GZ credit spread on a constructed firm-specific measure of expected default and a vector of bond-specific characteristics. They take the fitted GZ spread value of this regression for each firm, they average it out and the difference between this measure and the GZ credit spread index is the so-called excess bond premium, EBP.\footnote{To measure a firm's probability of default they use Merton (1974). Intuition: they assume a firm is a call option and they evaluate the risk of default with Black-Scholes-Merton option-pricing framework.}

The EBP is countercyclical and strongly peaks during the financial crisis. According to their estimates, both the EBP and fitted GZ spread contain significant independent explanatory power for key aggregate macroeconomic variables over 1 and 4 quarters. Moreover, in general, the economic impact of the excess bond premium is more than twice as large as that of the predicted component of the GZ credit spread. In addition, they run a quarterly SVAR where the identifying assumption implied by this recursive ordering is that shocks to the excess bond premium affect economic activity and inflation with a lag, while financial variables can react contemporaneously to such financial disturbance. An EBP shock causes significant reduction in real economic activity and the drop of investment is much more severe and persistent. These innovations account for more than 10\% of variations in output and 25\% in investment over business cycle horizons.

\textbf{Interpretation.} The macro dynamics are consistent with the notion that the EBP provides a timely and useful gauge of credit supply conditions. A reduction in the supply of credit - an increase in the excess bond premium - causes a drop in asset prices and a contraction in economic activity through the financial accelerator mechanisms emphasized in the literature. This reduction in the bearing capacity of financial intermediaries leads to an increase in the excess bond premium and a reduction in the supply of credit available to potential borrowers - both within the corporate cash market and through other sources of external finance. They confirm this result showing that EBP is related to ROA of financial intermediaries and other measures. Taken together, the evidence presented is consistent with the view that systematic deviations in the pricing of corporate bonds relative to the expected default risk of the underlying issuer reflect shifts in the effective risk aversion of the financial sector. Increases in risk aversion lead to a decline in asset prices and a contraction in the supply of credit, both through the corporate bond market and the broader commercial banking sector, factors that contribute significantly to a resulting slowdown in economic activity.\footnote{However, given the inherent asymmetric feature of debt contracts, their results could also reflect the fact that prices of corporate bonds - compared to equity prices - are better able to capture the downside risks to economic growth. Thus, fluctuations in the EBP may be due in part to a small but time-varying risk of economic disaster (see Gourio, 2013 - AEJM). The idea is that uncertainty can be part of the story...}


\section{Gilchrist, Sim, and Zakrajsek (2014) - NBER WP}

How uncertainty fluctuations influence business cycle dynamics has traditionally been analyzed within the framework of irreversible investment. This approach to corporate resource allocation treats the firm's future investment opportunities as \textit{real options} and emphasizes the importance of waiting and staging flexibility when making investment decisions - in response to increased uncertainty, firms should wait and see until uncertainty is resolved and the project is more clearly successful. According to the canonical framework used to price risky debt, the return on levered equity resembles the payoff of a call option, whereas the bondholders face the payoff structure that mimics that of an investor writing a put option. An increase in the riskiness of the firm's assets benefits equity holders at the expense of bondholders, implying a rise in credit spreads to compensate bondholders for heightened uncertainty. To the extend that external finance is subject to agency and moral hazard problems, an increase in uncertainty will raise the user cost of capital, inducing a decline in investment spending. Specifically to this setting they ask how much of the impact of fluctuations in uncertainty on aggregate investment reflects capital adjustment frictions associated with irreversibility and how much of it can be attributed to distortions in the financial markets?

\textbf{Empirical Evidence.} They use a novel micro-level data set to document the tight link between corporate bond credit spreads and uncertainty and to shed light on how the interaction of uncertainty and credit spreads affects investment dynamics. From the Center for Research in Security Prices (CRSP) data base, we extracted daily stock returns for all U.S. nonfinancial corporations with at least five years of trading from July, 1 1963 to September, 30 2012. First, they remove the forecastable variation in daily excess returns using the standard (linear) factor model. In the second step, they evaluate the quarterly variance of the unforecastable daily excess returns. This last measure is an estimate of time-varying equity volatility for a specific firm. They then regress (static regression) credit spread of bond issued by a specific firm on idiosyncratic volatility and some financial controls. An increase in idiosyncratic uncertainty leads to a significant widening of credit spreads. in sum, this result strongly supports the notion that fluctuations in uncertainty affect financial conditions by significantly altering the level of credit spreads in the economy. They then turn their analysis on how the interaction of uncertainty and financial conditions affect investment dynamics. They regress business fixed investment on the firm-specific measure of idiosyncratic volatility, while controlling for the fundamental determinants of investment spending. They consider a dynamic specification using GMM \`a la Arellano and Bover (1995) where both uncertainty and credit spreads are treated as endogenous and are instrumented with their own lagged values. Fluctuations in uncertainty have economically large and statistically significant effects on capital spending. However, the adverse effect of increased uncertainty on investment spending is more than halved once the information content of credit spreads is taken into account. This result is thus consistent with the notion that changes in credit spreads are an important part of the mechanism through which fluctuations in idiosyncratic volatility influence investment dynamics. Finally they construct an aggregate proxy for idiosyncratic uncertainty by assuming the firm-specific measure of uncertainty follows an autoregressive process controlling for firm fixed effects, linear time trend and time fixed effects. This last variable captures shocks to idiosyncratic volatility that are common to all firms. They ran a SVAR with two different Cholesky specifications: (i) credit spreads can respond on impact to uncertainty shocks; (ii) credit spreads cannot respond on impact to uncertainty shocks. Responses of investment are consistent with previous analysis: larger in the first case and smaller (but still negative and significant) in the second case. Their results indicate that once uncertainty is orthogonalized with respect to contemporaneous level of credit spreads, the impact of uncertainty shocks on economic activity is significantly attenuated. 

\textbf{Model.} They feature heterogeneous firms which faces technology, uncertainty and financial shocks. Firms accumulate capital subject to two types of adjustment frictions: fixed costs and partial irreversibility. In simple words, a positive level of investment is related to a fixed cost and a negative level of investment is related to a lower price of liquidated capital: these frictions increase the inaction regions of firms' investment. Moreover, firms are subject to a financial constraint related to the value of capital a la Kiyotaki and Moore. The main tradeoff the firm faces is that by increasing its leverage, the firm improves its current cashflow but increases the chance of a future liquidity shortfall, thereby raising the likelihood that it will have to issue costly new shares in the future. In their model, uncertainty and capital liquidity shocks cause fluctuations in aggregate investment by perturbing the tradeoff between the beneficial effects of capital accumulation on firm's ability to borrow and the increased risk of having tap costly equity finance to maintain its operations. The essential mechanism is that an increase in uncertainty or a decline in the resale value of capital (financial shock) both damp down the positive effect of investment by making bond yields rise more sharply as firms scale up capital expenditures. They calibrate the model with standard parameters in the literature. When they plot IRFs they compare model with financial frictions versus model without financial frictions. Similarly to Khan e Thomas (2008) irreversibilities, nonconvex adjustment frictions, and financial frictions do not play a large role with technology shocks. Instead, financial frictions explain the 90\% of the movements of all the variables after an uncertainty shocks. According to the standard irreversibility theory, aggregate investment dynamics, especially in response to fluctuations in uncertainty, will primarily reflect the firms' adjustment at the extensive margin - a jump in uncertainty raises the option value of waiting, which increases the proportion of firms in the inactive region. Moreover, the correlation between the average level of capital expenditures and uncertainty is essentially zero.\footnote{This result is consistent with the conventional wisdom that the response of aggregate investment to uncertainty shocks in a model with irreversibilities and nonconvex adjustment frictions reflects primarily adjustment at the extensive margin.} These results change dramatically once they add financial frictions. This correlation drop to -0.7 since the increase in credit spread implies a reduction of the capital target on active firms: intensive margin. In other words, the resulting deterioration in borrowing terms implies a significant increase in the user cost of capital, which leads firms to slash capital expenditure and delever, as evidenced by the response of debt relative to that of capital stock. They also plot IRFs for a financial shock. Responses are basically observationally equivalent to an uncertainty shock.\footnote{This is the point I do not like of the model: they are basically theorizing that the two shocks are identical.} They argue that small variation in the liquidation price of capital generates extremely large fluctuations - in their model is true! 

They conclude arguing that financial distortions due to agency problems between financial market participants are an important part of the transmission mechanism by which fluctuations in volatility affect the economy. Model simulation indicate that financial frictions are a powerful conduit through which uncertainty shocks affect aggregate investment. A jump in uncertainty leads to a sharp and persistent widening of credit spreads, which induces firms to simultaneously slash capital expenditures and delever. 

\section{Nimark (2014) - AER}

Unusual events are more likely to be considered newsworthy than events that are commonplace. When the availability of a signal depends on the realized value of the variable of interest, the availability of the signal is itself informative. The man-bites-dog mechanism provides a story for how economic agents come to understand that conditional uncertainty has increased. In the model presented here, a large shock in levels is more likely to generate a man-bites-dog signal and thus more likely to lead to an increase in the conditional uncertainty. In this case the causality runs from realizations of first moment shocks to conditional uncertainty. The same parameter restrictions that ensure that the posterior variance increases after a man-bites-dog signal also imply that the cross-sectional dispersion of expectations increases. In the data, we observe a positive correlation between the cross-sectional dispersion of forecasts and the absolute magnitudes of changes in macro-aggregates. Interpreted through the lens of the model, this suggests that the empirically relevant specification of the model may be one where the increase in uncertainty from conditioning on the availability of a man-bites-dog signal is dominating the increased in precision due to the content of the signal.

A signal $y$ about a latent variable $x$ will be called a man-bites-dog signal if it is more likely to be available when the realization of $x$ is more unusual in the sense of having a lower unconditional probability of occurring. When the availability of the signal $y$ depends on the realized value of $x$, the availability of $y$ by itself carries information about $x$ independently of the particular realized value of the signal $y$. In particular, conditional on the signal $y$ being available, the relative probability of unusual events increases. Denote the unconditional probability density function of the latent variable of interest $x$ as $p(x)$. An unusual realization of $x$ is thus a realization for which $p(x)$ is small. To help distinguish between a particular realization of the signal $y$ and the event that the signal $y$ is available, the indicator variable $S$ is defined to take the value $1$ when the signal $y$ about $x$ is available and $0$ otherwise. 

The signal is said to be a man-bites-dog signal if for any two realizations of $x$ denoted $x'$ and $x''$ such that
$$
p(x') < p(x'') \ \ \iff \ \ p(S = 1| x') > p(S = 1 | x'').
$$
which implies
$$
\frac{p(x'|S=1)}{p(x''|S=1)} > \frac{p(x')}{p(x'')} 
$$
The first inequality establishes that $x'$ is more unusual than $x''$. The second inequality formalizes the notion that a more unusual realization of $x$ is considered more newsworthy (entailing $y$) than a more common common realization. The third inequality implies that the availability of a man-bites-dog signal thus implies that probability mass should be redistributed away from unconditionally more likely outcomes toward relatively less likely outcomes. A man-bites-dog information structure thus introduces a form of conditional heteroscedasticity in the distribution of $x$. From the agents' perspective, it is as if the latent variable $x$ is drawn from a more dispersed distribution when the signal $y$ is available compared to when it is not. It is important to note that this is true even when the signal content of $y$ is not specifically about the variance, or second moment of, $x$.

There are two types of signals. Agent $j$ can always observe the private signal $x_j$ which is the sum of the true $x$ an idiosyncratic noise term
	$$
x_j = x + \varepsilon_j, \ \ \ \varepsilon \sim N(0, \sigma^2_{\varepsilon})
$$
where the variance of the idiosyncratic noise term $\varepsilon_j$ is common across agents. there also exists a public signal $y$
$$
y = x + \eta, \ \ \ \eta \sim N(0, \sigma^2_{\eta})
$$
Moreover, assume that
	$$
	p(x|S=0) = N(0,\sigma^2) \ \ \ \text{and} \ \ \ p(x|S=1) = N(0, \gamma \sigma^2)
	$$
Imposing the restriction $\gamma > 1$ ensures that the conditional probability $p(S=1|x)$ of observing the signal $y$ is increasing in the absolute value of $x$.

Agent $j$ conditional expectations of $x$ are then given by
$$
E[x|\Omega^{S=0}_j] = \frac{\frac{1}{\sigma^2_{\varepsilon}}}{\frac{1}{\sigma^2_{\varepsilon}} + \frac{1}{\sigma^2}}x_j
$$ 
and
$$
E[x|\Omega^{S=1}_j] = \frac{\frac{1}{\sigma^2_{\varepsilon}}}{\frac{1}{\sigma^2_{\varepsilon}} + \frac{1}{\sigma_{\eta}^2} + \frac{1}{\gamma \sigma^2}}x_j + \frac{\frac{1}{\sigma^2_{\eta}}}{\frac{1}{\sigma^2_{\varepsilon}} + \frac{1}{\sigma_{\eta}^2} + \frac{1}{\gamma \sigma^2}}y
$$

The posterior variances are also given by
$$
E \big[x - E[x|\Omega^{S=0}_j] \big]^2 = \bigg( \frac{1}{\sigma^2_{\varepsilon}} + \frac{1}{\sigma^2}  \bigg)^{-1}
$$
and
$$
E \big[x - E[x|\Omega^{S=1}_j] \big]^2 = \bigg( \frac{1}{\sigma^2_{\varepsilon}} + \frac{1}{\sigma_{\eta}^2} + \frac{1}{\gamma \sigma^2}  \bigg)^{-1}
$$
He can prove that the cross-sectional average expectation of $x$ responds more strongly to $x$ when $y$ is available. Intuitively, agents are willing to update their expectations further when they know that a tail realization is more likely to have occurred. Moreover, the posterior uncertainty about $x$ is larger when the signal $y$ is observed if
$$
\sigma^2_{\eta} > \frac{\sigma^2}{1 - \sigma^{-1}}
$$
The event that the signal $y$ is available make agents redistribute probability mass toward the tails of the distribution. This increases uncertainty. But observing the contents of the signal $y$ is informative about the location of $x$ which decreases uncertainty. Clearly, this second effect will be weaker when the signal is very noisy. The same condition that deliver a higher posterior variance also delivers a larger cross-sectional dispersion of expectations about $x$.

The paper applies this idea to the static model of Morris and Shin (2002) and the dynamic model of Lorenzoni (2009). If it is useful you need to get back to there. 


\section{Kozeniauskas, Orlik, and Veldkamp (2018) - JME}

Uncertainty is not exogenous. People do not spontaneously become uncertain, for no good reason. Instead, people become uncertain after observing an event that makes them question future outcomes. What sorts of events can make agents uncertain in a way that shows up in all these disparate measures? Uncovering the answer to this question opens the door to understanding what this uncertainty shock is and why the aggregate economy fluctuates. This paper contributes to answering these questions in the following ways. First it shows that the various measures of uncertainty are statistically distinct. While most measures of uncertainty are positively correlated after controlling for the business cycle, even the most highly correlated measures have correlations that are far from unity and some measures have correlations close to zero. Thus, it is not obvious that these various measures of uncertainty are measuring the same shock to the economy.

To measure macro uncertainty, we would ideally like to know the variance of peoples' belief about future macro outcomes. A common proxy for this is the VIX, which is a measure of the future volatility of the stock market, implied by option prices. To the extend that macro outcomes are reflected in stock prices and we accept the assumptions underlying options pricing formulas, this is a measure of the unpredictability of future aggregate outcomes, or macro uncertainty. A second proxy of macro uncertainty is the average absolute error of GDP growth forecast. Assuming higher uncertainty is associated with more volatile future outcomes, forecast errors will be higher on average when uncertainty is higher.

The first question that they investigate is whether the different types of uncertainty are statistically distinct. The result show that the correlations fo all measures of uncertainty are far from one. The variation in the fluctuations of the three types of uncertainty raises the question of whether these are three independent phenomena that are all countercyclical, or whether they have a tighter link. To investigate this they assess whether there is a positive relationship between them that holds above and beyond the business cycle. We test this by regressing each measure of uncertainty on the other types of uncertainty controlling for real GDP growth rate. They log-detrend the data before performing the analysis. The results show that most of the uncertainty measures have a positive and statistically significant relationship with the other measures.

To make a sense of the facts about (i) macro uncertainty, (ii) higher-order uncertainty, (i.e. forecast disagreement) and (iii) micro dispersion, (i.e. dispersion of firms' outcomes) they need a model with uncertainty about some aggregate production-relevant outcome, a source of belief differences, and firms that use their beliefs to make potentially heterogeneous production decisions. They have three potential exogenous source to drive all the 3 types of uncertainty: 1. time-varying variance in the fundamental process; 2. time-varying variance of public signal noise; 3. time-varying public signal noise. 

\textbf{Theoretical Results.} 

\begin{itemize}
	\item Micro dispersion only captures uncertainty due to private differences in information.
	\item Micro dispersion systematically overestimates the component of idiosyncratic differences in information.
	\item Shocks to macro volatility generate positive covariances between all pairs of the three types of uncertainty and dispersion. 
\end{itemize}

Different types of uncertainty and dispersion are theoretically distinct. They are not mechanically linked and nor do they naturally fluctuate together. Only one of the possible sources of uncertainty shocks necessarily generates the positive correlation between all three types of uncertainty and dispersion that we see in the data. Therefore, it is erroneous to threat these types of uncertainty and dispersion as single unified phenomenon, as the existing uncertainty shocks literature has tended to. If we want to unify these various shocks then we need a theory that ties them together. If we are looking for a common origin for the various uncertainty and dispersion shocks, then changes in macro volatility are a possible source. The key to this mechanism is that the public information - past outcomes - become less informative predictors of the future, relative to private information. This makes agents put less weight on the public information, more weight on private information, and leads them to disagree more.  Finally, when weak macro outcomes make highly-uncertainty disaster outcomes more likely (skewness), uncertainty of all types move in a correlated, volatile, and countercyclical way.

\section{Kozlowski, Veldkamp, and Venkateswaran (2018) - NBER Macro Annual}

Interest rates on safe assets fell sharply during the 2008 financial crisis. This is not particularly surprising: there are many reasons, from an increase demand for safe assets to monetary policy responses, why riskless rates fall during a period of financial turmoil. However, even after financial market calmed down, this state of affair is persisted. In fact, by 2017, several years after the crisis, government bond yields still show no sign of rebounding. Looking at longer term rates allows us to abstract from transitory monetary policy and interpret the graph as evidence of a persistent decline in the level of riskless interest rates. They seek to explain the fact that interest rates fell (relative to its long-run trend) during the financial crisis and failed to rebound. 

The main contribution of this paper is to explain why tail risk fluctuates and show how an extreme event like the Great Recession can induce a persistent drop in riskless rates. Before the financial crisis hit, most people in the US thought that such crises only happened elsewhere and that bank runs were a topic for historians. Observing the events of 2007-09 changed those view. But formalizing this story requires a departure from the standard rational expectations paradigm, where the distributions of all random events are assumed to be known. We need a machinery that allows agents to not know the true distribution, so that upon seeing something they thought should not happen, they can revise their beliefs. A realistic, quantifiable and tractable way to depart from full knowledge distribution is treating agents like classical econometricians. The agents in our model have a finite dataset - the history of all realized shocks - and they estimated the distribution from which those shocks are drawn. In order to be agnostic on the distribution of these shocks, they take a non-parametric approach and let the data inform the shape of the distribution. Agents take all the data they have observed and use a kernel density procedure to estimate the probability distribution from which these data were drawn. In this case an extreme shock tends to lead very persistent effect on the estimated distribution. This persistence has its origins in the so-called martingale property of beliefs, i.e. conditional on time $t$ information, the estimated distribution is a martingale. Thus, on average, the agent expects her future belief to be the same as her current beliefs. This implies that beliefs will revert. However, the rate at which this occur is very slow. This has to do with the fact that under their non-parametric approach, outlier observations play a crucial role in learning about the frequency of tail events. Ordinary events are just not very informative about those tail probabilities. And since data on tail events is scarce, observing one makes the resulting belief revisions large and extremely persistent (even if they are ultimately transitory).

They analyze a simple RBC model where the firm is subject to an i.i.d. aggregate shock on capital quality which is not observed by the agents and is estimated via methods presented above. These shocks are a simple if imperfect, way to model the extreme and unusual effect on the 2008-09 recession on the economic value and returns to non-residential capital. It allows to capture the idea that a hotel built in 2007 in Las Vegas may still be standing after the Great Recession, but may deliver much less economic value. In addition, firms have access to a productive opportunity, but require liquidity in the form of pledgeable collateral in order to exploit it. Capital and riskless bonds both can be pledged, albeit to different degrees. Bonds are fully pledgeable, but only a fraction of the effective capital can be used as collateral. The investment in the project cannot exceed the sum of pledgeable collateral. An increase in tail risk now has an additional effect - it reduces the liquidity value of capital, increasing the demand for an alternative source of liquidity, namely riskless government bonds, amplifying the interest rate response. They calibrate the model rather seriously and derive the shocks to the quality of capital formally by the data. The rise in tail risk causes the economy to invest and produce less, leading to lower output and capital. This occurs because investing now has a lower mean return but it is also significantly riskier. The change in beliefs leads to a sharp drop in the riskfree rate. There are two forces which contribute to this drop. First, future consumption is riskier, which has the usual effect of lowering the required return on riskfree claims. Second, the liquidity premium raises because there is less liquidity in the economy (due to lower levels of capital in the new steady state) and more liquidity risk. Consistent with their information acquisition belief the economy remains depressed for a prolonged period. 


\section{McDonald, and Siegel (1986) - QJE}


Suppose that a firm is considering building a synthetic fuel plant. What is the appropriate way to decide whether or not to build? Clearly, one calculates the present values of profits and direct costs of construction. It would be incorrect, however, simply to compare these present values and build the plant if the present value of profits exceed the direct costs. The decision to build the plant is irreversible; the plant cannot be used for any other purpose. The decision to defer building, however, is reversible. This asymmetry, when properly taken into account, leads to a rule that says build the plant only if benefits exceed the costs by a certain positive amount. The correct calculation involves comparing the value of investing today with the present value of investing at all possible times in future. This is a comparison of mutually exclusive alternatives. In this paper they explore the practical importance of the value of waiting to invest, assuming that investment timing decisions are made by risk-averse investors.

At any $t$, the firm can pay $F_t$ to install an investment project, for which expected future net cash flows conditional on undertaking the project have a present value $V_t$. The uncertainty is that both $F_t$ and $V_t$ are known today but unknown the value they might take tomorrow, implying that the firm does not know for sure if it is more convenient to invest today or tomorrow. The result is that when uncertainty is larger, then the threshold $T_t = V_t - F_t$ gets larger together with the value of the investment option. When both $V_t$ and $F_t$ are expected to fluctuate more than it is worth to wait more for a larger return. 

\section{Forni, Gambetti, and Sala (2017) - Working Paper}

The starting point of the present work is the idea that uncertainty arises from news. The definition of uncertainty they focus on is the forecast error variance. Economic agents live in world with imperfect information, observe new important events, but cannot predict exactly their effects on economic activity. This increase the forecast error variance, i.e. uncertainty. In other words, news have both a first-moment effect on the expected valuers and a second-moment effect on the variance of the forecast error. Of course, it is conceivable that some news affect uncertainty without affecting expectations, or vice-versa. If nothing new happens, expectations do not change and uncertainty is low. By contrast, when important events occur, expectations change substantially and, given that the true magnitude of the event is unknown, uncertainty increases. It is important to stress that uncertainty is not an endogenous variable, caused by business cycle fluctuations. Rather, it is quiet the contrary: news-driven uncertainty is a genuine, independent source of business cycle fluctuations, which arises in combination with news shocks.

They use a specific variable of the Michigan index to show that no news are negative correlated with uncertainty and squared news are positively correlated with all uncertainty index, with correlation coefficients ranging from $0.62$ to $0.69$. In the empirical part, they use standard VAR techniques to evaluate the interaction between news shocks and uncertainty. In particular, they use a 2-step procedure: (i) they separately evaluate a news shock and extract the series, (ii) they add this series and its squared values in a second VAR which takes the form of a VARX to evaluate the interaction between uncertainty and news. When the quadratic effect is taken into account, the business-cycle consequences of news appear more complex than usually believed. First, news shocks below average reduce uncertainty, producing a temporary upturn of economic activity. A zero news shock, for instance, implies a zero first-moment effect, but a positive uncertainty effect. In this sense, no news is good news. Second, the response of output to positive and negative news is generally asymmetric. For small shocks,the uncertainty effect is positive; it therefore mitigates the negative first-moment effect of bad news and reinforces the positive effect of good news. For large shocks, the asymmetry is reversed. The uncertainty effect is negative; it therefore exacerbates the negative first moment effect of bad news and reduce the positive impact of good news. Third, the density distribution of the squared news shock is of course highly skewed, with a large fat tail on the right-hand side. As a consequence, positive uncertainty effects cannot be large, whereas negative effects can.

\section{Smietanka, Bloom, and Mizen (2018) - Working Paper}

The Lehman Brothers event in 2008 was the largest economic shock to the financial system since the Great Depression. It triggered a slowdown in economic activity known as the Great Recession, which was unusual for its long duration. At the same time economic uncertainty increased, this connection is now a defining feature of the post-crisis period. What is rather less well known is the effect of higher uncertainty over this period on decisions made at the level of the firm concerning investment, dividends payout and cash holding. By investigating the connection between business decisions and the rise in economic uncertainty they aim to provide more information that will help understand the puzzlingly low level of investment after crisis. They use individual firm-level data and control for the many influences on firm-level decisions, focusing on economic uncertainty as a key explanatory variable. They will also observe any relationship between higher uncertainty and lower dividend payouts and the increase in cash holding. Theory argues that irreversibility of investment and the real option value of waiting would create incentives for firms to delay making investment whenever uncertainty is high. 

They measure total uncertainty as the square root of the average subjective individual variances of forecasters plus the extent of their average disagreement. Subjective uncertainty and average disagreement are equally weighted. To calculate the value of our measure of uncertainty they use data from the Survey of External Forecasters compiled by the Bank of England from up to 37 professional forecasters each quarter since 1998q1. What distinguishes this survey from other surveys of economic forecasters and makes it so valuable for our analysis is the fact that each respondent provides his/her forecast in the form of a histogram that has a similar distribution to the responses of the Decision Maker Panel. Data on firms' balance sheets, cash flow and income statements are drawn from Bloomberg to provide an unbalanced panel of over 10000 UK listed firm-year observations over the period 1998 to 2015. To measure the effect of uncertainty on investment they expand a simple version of the stochastic Tobin,s Q model to investigate the uncertainty investment relation. Cash flow rations and sales growth rate are included to allow for the potential constraints on the investment by firms that cannot access the external finance. They measure the effect on cash holding over total assets controlling for total debt, net working capital and investment among others. Finally, they measure the effect of uncertainty on the dividend-to-earnings ratio controlling for many measures as total debt, cash, sales growth, among others. Using both OLS and dynamic fixed-effects GMM model they robustly obtain that investment and dividends are negatively associated with higher uncertainty and cash holding is positively related.


\section{Alfaro, Bloom, and Lin (2018) - NBER WP}

As Stock and Watson (2012) noted, uncertainty shocks and financial shocks are highly correlated. Are these the same shock, or are they distinct shocks with an interrelated impact, in which uncertainty is amplified by financial frictions? This paper relates to three main literatures. First, the large uncertainty literature studying the impact of heightened uncertainty and volatility on investment and employment. We build on this literature to show the joint importance of real and financial frictions for investment, hiring, and financial dynamics, and importantly how adding financial shocks can roughly double the impact of uncertainty shocks. Second, the literature on financial frictions and business cycles. We build on this literature to argue it is not a choice between uncertainty shocks and financial shocks as to which drives recessions, but instead these shocks amplify each other so they cannot be considered individually. Finally, the finance literature that studies the determinants of corporate financing choices. We are complementary to these studies by showing that uncertainty shocks have significant impact on firms' real and financial flows, examined in both calibrated macro models and well identified micro-data estimations. 

The model features a continuum of heterogeneous firms facing uncertainty shocks and financial frictions. Furthermore, financial adjustment costs vary over time and across firms. Firms choose optimal levels of physical capital and investment, labor, and cash holding each period to maximize the market value of equity. When the sum of investment in capital, investment adjustment cost and investment in cash exceeds the operating profit, firms can take external funds by issuing equity. External equity financing is costly for firms. Cost of financing can change over time and firms do not incur costs when paying dividends or repurchasing shares. So, the shock captures the marginal cost of external financing which affects both optimal investment and cash holding policies. After an uncertainty shock capital and labor drop and recover due to increased real-option effects leading firms to pause investing (and thus hiring by the complementarity of labor and capital), while depreciation continues to erode capital stocks. TFP falls and recovers due to the increased mis-allocation of capital and labor after uncertainty shocks. Dividend payout rises because firms with excess capital disinvest more with high uncertainty and hence payout more. After a financial shock, firms increase cash holdings and cut dividends payout due to increased financing costs. Output, labor and capital falls and then recover. Finally, when the two shocks are performed together they lead to drops in output, capital, labor and TFP by a significant larger size. 

Stock returns are from CRSP and annual accounting variables are from Compustat. The sample period is from January 1963 through December 2016. Compustat variables are at the annual frequency. Their main firm-level empirical tests regress changes in real and financial variables on 12-month lagged changes in uncertainty, where the lag is both to reduce concerns about contemporaneous endogeneity and because of natural time to build delays. Moreover, their main tests include both firm and time (calendar year) fixed effects. In measuring firm-level uncertainty we employ both realized annual uncertainty from CRSP stock returns and option-implied uncertainty from OptionMetrics. Our identification strategy exploits firms; differential exposure to aggregate uncertainty shocks in energy, currency, policies, and treasuries to generate exogenous changes in firm-level uncertainty. The idea is that some firms are very sensitive to oil prices while others are not, so that when oil-price volatility rises it shifts up firm-level volatility in the former group relative to the latter group. Their estimation approach is conceptually similar to classic Bartik identification strategy which exploits different regions exposure to different industry level shocks. 

In all cases they find that uncertainty shocks lead to significant drops in firm-level investment. Moreover, realized and implied volatility shocks are negatively related to future changes in intangible capital investment, employment, and cost of goods sold. Finally, uncertainty decrease the willingness of firm's to increase their overall debt. Consistent with a precautionary savings motive, rises in firm uncertainty causes a large reduction in cash dividend payout and an increase in cash reserves ans short-term liquid instruments. To address the concern of endogeneity to financial shocks they include a variety of different controls for firms financial conditions and show their baseline results are robust to this. 

\section{Bloom (2009) - Econometrica}

Uncertainty appears to dramatically increase after major economic and political shocks like the Cuban missile crisis, the assassination of JFK, the OPEC I oil-price shock, and the 9/11 terrorist attack. Structural VAR evidence shows an important impact of those shocks on economic activity. Uncertainty is also a ubiquitous concern of policymakers. For example, after 9/11 the FOMC worried about exactly the type of real-options effects analyzed in this paper. The primary contribution of this paper is to structural analyze these types of uncertainty shocks. This is achieved by extending a standard firm-level model with a time-varying second moment as the driving process and a mix of labor and capital adjustment costs. The model yields a central region of inaction in hiring and investment space due to nonconvex adjustment costs. Firms only hire and invest when business conditions are sufficiently good, and only fire and disinvest when they are sufficiently bad. When uncertainty is higher, the inaction region expands and firms become more cautious in responding to business conditions. He uses this model to simulate the impact of a large temporary uncertainty shock and find that it generates a rapid drop, rebound, and overshoot in employment, output, and productivity growth. Productivity slows down because the drop in hiring and investment reduces the rate of reallocation from low to high productivity firms. He then evaluates the robustness of these predictions to general equilibrium effects, which for computational reasons are not included in the baseline model. Results seem to be robust to general equilibrium effects. The reason is that the rise in uncertainty following a second-moment shock not only generates a slowdown in activity, but it also makes firms temporarily extremely insensitive to price changes. This raise a second policy implication that the economy will be particularly unresponsive to monetary or fiscal policy immediately after an uncertainty shock, suggesting additional caution when thinking about the policy response to these types of events. More generally, the framework in this paper also provides response to the \textit{where are the negative productivity shocks?} critique of real business cycle theories. In particular, since second-moment shocks generate large falls in output, employment, and productivity growth, it provides an alternative mechanism to first-moment shocks for generating recessions. 


\textbf{Data Analysis.} He runs a VAR where he identifies uncertainty as a dummy variable which take zero when VXO is low and takes one when VXO is high. Responses are short-run effect with an overshoot in the medium run. Economic activities and productivity slow down in the short run and slightly increase in the medium run.  

\textbf{Model.} I did not read the model yet. If you need to write model, this one should be read before. 




\end{document}

